{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import random\n",
    "from textwrap import dedent\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import trange\n",
    "import json\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    is_negatable: bool\n",
    "    negated_question: str\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from filelock import FileLock\n",
    "\n",
    "\n",
    "CACHE_FILE = \"response_cache.json\"\n",
    "LOCK_FILE = \"response_cache.lock\"\n",
    "\n",
    "lock = FileLock(LOCK_FILE)\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Load cache from file safely with a file lock to prevent corruption.\"\"\"\n",
    "    with lock:  # Ensures only one process/thread reads/writes at a time\n",
    "        if os.path.exists(CACHE_FILE):\n",
    "            with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    return json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    return {}  # If corruption occurs, reset cache\n",
    "        return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    \"\"\"Save cache to file safely with a file lock.\"\"\"\n",
    "    with lock:\n",
    "        with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(cache, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def hash_inputs(system_prompt, user_prompt, output_format):\n",
    "    \"\"\"Create a unique hash for a given input.\"\"\"\n",
    "    data = f\"{system_prompt}|{user_prompt}|{output_format}\"\n",
    "    return hashlib.sha256(data.encode()).hexdigest()\n",
    "\n",
    "def get_reply(client, system_prompt, user_prompt, output_format):\n",
    "    \"\"\"Get a reply from the model or retrieve it from cache with atomicity.\"\"\"\n",
    "    input_hash = hash_inputs(system_prompt, user_prompt, output_format)\n",
    "\n",
    "    with lock:  # Prevent multiple processes from modifying cache at the same time\n",
    "        cache = load_cache()  # Read latest cache\n",
    "\n",
    "        if input_hash in cache:\n",
    "            # print(\"Using cached response\")\n",
    "            return cache[input_hash]  # Return cached response immediately\n",
    "\n",
    "    # If not in cache, query the model (without holding lock to avoid blocking other threads)\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": dedent(system_prompt)},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": dedent(user_prompt)},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        response_format=output_format,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    parsed_output = completion.choices[0].message.parsed.dict()\n",
    "\n",
    "    with lock:  # Ensure only one process updates cache at a time\n",
    "        cache = load_cache()  # Reload latest cache to prevent overwrites\n",
    "        cache[input_hash] = parsed_output\n",
    "        save_cache(cache)\n",
    "\n",
    "    return parsed_output\n",
    "\n",
    "\n",
    "# def get_reply(client, system_prompt, user_prompt, output_format):\n",
    "    \n",
    "#     completion = client.beta.chat.completions.parse(\n",
    "#         model=\"gpt-4o\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": dedent(system_prompt)},\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": dedent(user_prompt)},\n",
    "#                 ],\n",
    "#             },\n",
    "#         ],\n",
    "#         response_format=output_format,\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     parsed_output = completion.choices[0].message.parsed.dict()\n",
    "#     return parsed_output\n",
    "\n",
    "api_key = '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'\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "improved_prompt = \"\"\"\n",
    "**Task:**  \n",
    "You will be given an question collected from existing visual question answering datasets. Your task is to produce a minimally modified, negated version of the question by inserting a negation (e.g., \"not\", \"do not\", \"isn't\", etc.) in a way that:\n",
    "\n",
    "1. **Minimal Changes:** Alters the original question as little as possible.\n",
    "2. **Answer Inversion:** Causes the original correct answer to become incorrect while making one of the originally incorrect answers correct.\n",
    "3. **Linguistic Accuracy:** Adheres to proper grammar and preserves the semantic intent of the question.\n",
    "\n",
    "**Special Case:**  \n",
    "1. Do not negate any background that is provided along with the question (e.g., mathematical conditions, background information, etc). Only negate the question itself (usually the last sentence).\n",
    "2. If it is not possible to create a valid negation that meets these criteria, return an empty string for the negated question and set the flag `is_negatable` to `false`.\n",
    "\n",
    "**Output Format:**  \n",
    "Your response should be an object with the following structure:\n",
    "{\n",
    "  \"negated_question\": \"<your negated question (with original background information) here, or an empty string if not negatable>\",\n",
    "  \"is_negatable\": <true/false>\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Load your data.\n",
    "data = [json.loads(line) for line in open(\"../robust_vqa/VMCBench-9018.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 337/9018 [00:20<01:32, 94.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 3059: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=16384, prompt_tokens=432, total_tokens=16816, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "Error processing item 3074: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=16384, prompt_tokens=413, total_tokens=16797, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "Error processing item 2912: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=16384, prompt_tokens=424, total_tokens=16808, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 451/9018 [05:48<2:51:34,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 450: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=16384, prompt_tokens=750, total_tokens=17134, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2871/9018 [05:50<09:32, 10.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 2870: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=16384, prompt_tokens=417, total_tokens=16801, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9018/9018 [06:25<00:00, 23.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_item(idx_item):\n",
    "    idx, item = idx_item\n",
    "    # Skip if already processed.\n",
    "    if 'negated_question' in item:\n",
    "        return idx, item\n",
    "    \n",
    "    question = item['question']\n",
    "    user_prompt = f\"Question: {question}\"\n",
    "    \n",
    "    # Call your API/function to get the negated question.\n",
    "    try:\n",
    "        negated_question = get_reply(client, improved_prompt, user_prompt, Question)\n",
    "    except Exception as e:\n",
    "        negated_question = {\"negated_question\": \"\", \"is_negatable\": False}\n",
    "        print(f\"Error processing item {idx}: {e}\")\n",
    "    item[\"negated_question\"] = negated_question\n",
    "    return idx, item\n",
    "\n",
    "# Choose an appropriate number of workers.\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    # executor.map returns results in order, but we want progress tracking so we wrap it in tqdm.\n",
    "    _ = list(tqdm(executor.map(process_item, enumerate(data)), total=len(data)))\n",
    "\n",
    "# save data as \"VMCBench-9018-negated.jsonl\"\n",
    "with open(\"VMCBench-9018-negated.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7379 out of 9018 questions are negatable.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import copy\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "data = [json.loads(line) for line in open(\"VMCBench-9018-negated.jsonl\")]\n",
    "negatable_data = [item for item in data if item['negated_question']['is_negatable']]\n",
    "print(len(negatable_data), \"out of\", len(data), \"questions are negatable.\")\n",
    "\n",
    "\n",
    "with open(\"VNBench-7379.jsonl\", \"w\") as f:\n",
    "    for item in negatable_data:\n",
    "        correct_choice = item[item['answer']]\n",
    "        incorrect_choices = [item[key] for key in 'ABCD' if key != item['answer']]\n",
    "        incorrect_choice = random.sample(incorrect_choices, 1)[0]\n",
    "\n",
    "        choices = [correct_choice, incorrect_choice]\n",
    "        random.shuffle(choices)\n",
    "\n",
    "        new_item = copy.deepcopy(item)\n",
    "        new_item.pop('negated_question')\n",
    "\n",
    "        new_item['original_question'] = item['question']\n",
    "        new_item['negated_question'] = item['negated_question']['negated_question']\n",
    "        new_item['A'] = choices[0]\n",
    "        new_item['B'] = choices[1]\n",
    "\n",
    "        new_item['original_answer'] = \"AB\"[choices.index(correct_choice)]\n",
    "        new_item['negated_answer'] = \"AB\"[choices.index(incorrect_choice)]\n",
    "\n",
    "        new_item.pop('question')\n",
    "        new_item.pop('answer')\n",
    "        new_item.pop('C')\n",
    "        new_item.pop('D')\n",
    "        f.write(json.dumps(new_item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = [json.loads(line) for line in open(\"VNBench-7379.jsonl\")]\n",
    "\n",
    "with open(\"VNBench-7379-original.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        new_item = copy.deepcopy(item)\n",
    "        new_item[\"question\"] = item[\"original_question\"]\n",
    "        new_item[\"answer\"] = item[\"original_answer\"]\n",
    "    \n",
    "        f.write(json.dumps(new_item) + \"\\n\")\n",
    "\n",
    "with open(\"VNBench-7379-negated.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        new_item = copy.deepcopy(item)\n",
    "        new_item[\"question\"] = item[\"negated_question\"]\n",
    "        new_item[\"answer\"] = item[\"negated_answer\"]\n",
    "    \n",
    "        f.write(json.dumps(new_item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3651 out of 7379 questions have correct answer A.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = [json.loads(line) for line in open(\"VNBench-7379.jsonl\")]\n",
    "\n",
    "# how many questions with correct answer A?\n",
    "print(len([item for item in data if item['original_answer'] == 'A']), \"out of\", len(data), \"questions have correct answer A.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the room adjacent to the kitchen?\n",
      "What is not the room adjacent to the kitchen?\n",
      "\n",
      "what is the bottom word?\n",
      "what is not the bottom word?\n",
      "\n",
      "If cricket was removed from the food web, there would be\n",
      "If cricket was not removed from the food web, there would be\n",
      "\n",
      "Select the correct cross-section from the A-A cross-section in the following figure( )<image 1>\n",
      "Select the incorrect cross-section from the A-A cross-section in the following figure( )\n",
      "\n",
      "Which is the top predator in the food web?\n",
      "Which is not the top predator in the food web?\n",
      "\n",
      "What language is the text in this picture written in?\n",
      "What language is the text in this picture not written in?\n",
      "\n",
      "Who wrote this book?\n",
      "Who did not write this book?\n",
      "\n",
      "Which model can achieve the best ImageNet 10-shot Accuracy score?\n",
      "Which model cannot achieve the best ImageNet 10-shot Accuracy score?\n",
      "\n",
      "What was the market value of peer-to-peer consumer lending in France in 2018?\n",
      "What was not the market value of peer-to-peer consumer lending in France in 2018?\n",
      "\n",
      "What the gray item of clothing is called?\n",
      "What is the gray item of clothing not called?\n",
      "\n",
      "How many glasses are present in the image?\n",
      "How many glasses are not present in the image?\n",
      "\n",
      "Look at the diagram what is the cycle?\n",
      "Look at the diagram what is not the cycle?\n",
      "\n",
      "What is the man's left hand holding?\n",
      "What is the man's left hand not holding?\n",
      "\n",
      "what is the only years that total losses were below 350,000?\n",
      "what is not the only years that total losses were below 350,000?\n",
      "\n",
      "What is the predominant color of the shirts of the people in the image?\n",
      "What is not the predominant color of the shirts of the people in the image?\n",
      "\n",
      "Consider the following graph:Which one of the following cannot be the sequence of edges added, in that order, to a minimum spanning tree using Kruskal's algorithm?<image 1>\n",
      "Consider the following graph: Which one of the following can be the sequence of edges added, in that order, to a minimum spanning tree using Kruskal's algorithm?\n",
      "\n",
      "As shown in the figure, points A, B, and C are three points on ⊙O, and the straight line CD and ⊙O are tangent to point C. If ∠DCB = 40.0, then the degree of ∠CAB is ()\n",
      "As shown in the figure, points A, B, and C are three points on ⊙O, and the straight line CD and ⊙O are not tangent to point C. If ∠DCB = 40.0, then the degree of ∠CAB is ()\n",
      "\n",
      "What is the woman holding to her ear?\n",
      "What is the woman not holding to her ear?\n",
      "\n",
      "The Chrysler Building was designed by?<image 1>\n",
      "The Chrysler Building was not designed by?\n",
      "\n",
      "what is the total of seasons played between baltimore bullets and chicago stags?\n",
      "what is not the total of seasons played between baltimore bullets and chicago stags?\n",
      "\n",
      "What is the total percentage of people  who say that they do either less or more often than the usual amount of exercise during the coronavirus pandemic in the United States as of April 2020?\n",
      "What is the total percentage of people who do not say that they do either less or more often than the usual amount of exercise during the coronavirus pandemic in the United States as of April 2020?\n",
      "\n",
      "What radio station is displayed on the screen?\n",
      "What radio station is not displayed on the screen?\n",
      "\n",
      "What is the other name of Roger Federer?\n",
      "What is not the other name of Roger Federer?\n",
      "\n",
      "Which flavor was this?\n",
      "Which flavor was this not?\n",
      "\n",
      "what is activated by corporate-sponsored events?\n",
      "what is not activated by corporate-sponsored events?\n",
      "\n",
      "Which country is highlighted?\n",
      "Which country is not highlighted?\n",
      "\n",
      "which is characterized by convexity ?\n",
      "which is not characterized by convexity ?\n",
      "\n",
      "What is the name of the colony shown?\n",
      "What is not the name of the colony shown?\n",
      "\n",
      "What is in front of the vehicle that is on the left?\n",
      "What is not in front of the vehicle that is on the left?\n",
      "\n",
      "Which is the most narrow in this diagram?\n",
      "Which is not the most narrow in this diagram?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = [json.loads(line) for line in open(\"VNBench-7379.jsonl\")]\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "for item in random.sample(data, 30):\n",
    "    print(item['original_question'])\n",
    "    print(item['negated_question'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def get_image(image_base64):\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(io.BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# data = [json.loads(line) for line in open(\"VNBench-7379.jsonl\")]\n",
    "\n",
    "# # count category of data\n",
    "# from collections import Counter\n",
    "# counter = Counter([item['category'] for item in data])\n",
    "\n",
    "\n",
    "# # for each category, sample one question\n",
    "# import random\n",
    "# random.seed(1234)\n",
    "\n",
    "# for category in counter:\n",
    "#     print(category)\n",
    "#     print()\n",
    "#     category_data = [item for item in data if item['category'] == category]\n",
    "#     for item in random.sample(category_data, 2):\n",
    "#         print(item['negated_question'])\n",
    "#         print('A.', item['A'])\n",
    "#         print('B.', item['B'])\n",
    "#         print(item['negated_answer'])\n",
    "#         display(get_image(item['image']))\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = set()\n",
    "for item in data:\n",
    "    question = item['question']\n",
    "    # if question in questions:\n",
    "        print(f\"Duplicate question: {question}\")\n",
    "    questions.add(question)\n",
    "print(len(questions), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如图，直线l1∥l2，∠1＝50°，∠2＝75°，则∠3＝（）\n",
      "{'is_negatable': False, 'negated_question': ''}\n"
     ]
    }
   ],
   "source": [
    "idx = 500\n",
    "print(data[idx]['question'])\n",
    "question = data[idx]['question']\n",
    "user_prompt = f\"\"\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "negated_question = get_reply(client, improved_prompt, user_prompt, Question)\n",
    "print(negated_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"\\nI'm going to create a VQA benchmark dataset with negated questions. I'll give you the original question.\\nNegate the question by adding 'not' (such as be not, do not, which is not, etc) according to the semantic meaning of the question and linguistic grammar rules.\\nBy negating the question, make sure it will make the original correct answer incorrect, and any of the incorrect answer to be correct.\\nIf you cannot negate this question, return the empty string with the is_negatable flag set to false.\\nMake sure you do the minimal edits to the question to negate it.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [json.loads(line) for line in open(\"../robust_vqa/VMCBench-9018.jsonl\")]\n",
    "\n",
    "# for idx in trange(len(data)):\n",
    "#     if 'negated_question' in data[idx]:\n",
    "#         continue\n",
    "#     question = data[idx]['question']\n",
    "#     user_prompt = f\"\"\"\n",
    "#     Question: {question}\n",
    "#     \"\"\"\n",
    "\n",
    "#     negated_question = get_reply(client, improved_prompt, user_prompt, Question)\n",
    "#     data[idx][\"negated_question\"] = negated_question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
